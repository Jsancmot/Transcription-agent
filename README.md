# ğŸ¤ AI Transcription Agent

AplicaciÃ³n de transcripciÃ³n de audio con API REST y **Groq LLM**. Gestiona automÃ¡ticamente un historial de transcripciones.

## âœ¨ Features

- ğŸ¤– **Agente inteligente con Function Calling** - Entiende lenguaje natural sin comandos especÃ­ficos
- ğŸ¯ **TranscripciÃ³n precisa** con Deepgram API - Modelos de Ãºltima generaciÃ³n (Nova-2)
- ğŸš€ **LLM ultrarrÃ¡pido** usando Groq API (gratuito, 14,400 requests/dÃ­a)
- ğŸ’¬ **ComprensiÃ³n natural** - Habla como quieras, el agente te entiende
- ğŸ“Š **Historial automÃ¡tico** de todas las transcripciones en CSV
- ğŸŒ **API REST** con FastAPI para integraciÃ³n
- ğŸŒ **Multi-idioma nativo** - Funciona en espaÃ±ol, inglÃ©s, francÃ©s, etc. sin configuraciÃ³n
- ğŸ”§ **Extensible sin cÃ³digo** - Agrega herramientas con descripciones, sin modificar lÃ³gica
- ğŸ³ **Docker listo** para producciÃ³n

## ğŸ“‹ Prerrequisitos

- Python 3.11+ o Docker
- API Keys:
  - Groq API key (100% gratuita) - Para el agente LLM
  - Deepgram API key (gratuita con $200 crÃ©dito) - Para transcripciÃ³n de audio

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd Modulo2-1
```

### 2. Configurar API Keys

1. **Groq API** (gratuito):
   - Visita [https://console.groq.com](https://console.groq.com)
   - Crea cuenta gratuita
   - Genera API key
   - 14,400 requests por dÃ­a gratis

2. **Deepgram API** (gratuita con crÃ©dito):
   - Visita [https://console.deepgram.com/signup](https://console.deepgram.com/signup)
   - Crea cuenta gratuita
   - Recibe $200 en crÃ©ditos de inicio
   - Genera API key en el dashboard

3. Configurar variables de entorno:

```bash
# Copiar configuraciÃ³n
cp .env.example .env

# Editar .env con tus API keys:
# GROQ_API_KEY=tu_groq_key
# DEEPGRAM_API_KEY=tu_deepgram_key
```

## âš¡ Prueba RÃ¡pida

DespuÃ©s de iniciar el servidor, prueba el agente inteligente:

```bash
# Verificar que el servidor estÃ¡ corriendo
curl http://localhost:8000/health

# Probar el agente con diferentes mensajes naturales
curl -X POST http://localhost:8000/agent -F "message=quÃ© puedes hacer?"
curl -X POST http://localhost:8000/agent -F "message=dame el historial"
curl -X POST http://localhost:8000/agent -F "message=show me the last 3 transcriptions"
curl -X POST http://localhost:8000/agent -F "message=cuÃ¡ntas transcripciones hay?"
```

**Â¡Nota!** El agente entiende lenguaje natural - no necesitas comandos especÃ­ficos. Ver secciÃ³n [ğŸ’¬ GuÃ­a Completa](#-guÃ­a-completa-de-uso-del-agente-inteligente) para mÃ¡s ejemplos.

## ğŸ¯ Uso

### OpciÃ³n 1: Docker (Recomendado)

#### Construir imagen
```bash
docker build -t transcription-api .
```

#### Iniciar servidor
```bash
docker run -d -p 8000:8000 --env-file .env -v "$(pwd)/data/audio/uploads":/app/data/audio/uploads -v "$(pwd)/data/transcriptions":/app/data/transcriptions --name transcription-api-server transcription-api
```

#### Scripts automÃ¡ticos
```bash
# Linux/Mac
./start_server.sh

# Windows
start_server.bat
```

#### Detener servidor
```bash
# Linux/Mac
./stop_server.sh

# Windows
stop_server.bat
```

### OpciÃ³n 2: Local

#### Instalar dependencias
```bash
pip install -r requirements.txt
```

#### Iniciar servidor
```bash
python src/api_server.py
```

## ğŸ“ Uso de la API

### ğŸ¤– Endpoint Inteligente con Function Calling (Recomendado)

El agente usa **function calling nativo** para entender tu intenciÃ³n en lenguaje natural. **No necesitas comandos especÃ­ficos** - simplemente describe lo que quieres hacer.

#### Transcribir audio adjunto
```bash
curl -X POST http://localhost:8000/agent \
  -F "message=Por favor transcribe este archivo de audio" \
  -F "file=@tu_archivo.mp3"
```

#### Transcribir audio que ya estÃ¡ en la carpeta uploads
```bash
# Si ya tienes un archivo en data/audio/uploads/podcast.mp3
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe el archivo podcast.mp3 que estÃ¡ en uploads" \
  -F "file=@data/audio/uploads/podcast.mp3"

# O de forma mÃ¡s natural
curl -X POST http://localhost:8000/agent \
  -F "message=pasa a texto el podcast.mp3" \
  -F "file=@data/audio/uploads/podcast.mp3"
```

#### Consultar historial
```bash
curl -X POST http://localhost:8000/agent \
  -F "message=dame el historial de transcripciones"
```

#### Buscar contenido especÃ­fico
```bash
curl -X POST http://localhost:8000/agent \
  -F "message=busca transcripciones que mencionen proyecto"
```

### Endpoints Legacy (Directos)
Para cuando sabes exactamente quÃ© necesitas:

#### Transcribir archivo
```bash
curl -X POST "http://localhost:8000/upload?language=es" -F "file=@data/audio/uploads/tu_archivo.mp3"
```

#### Ver historial
```bash
curl -X GET http://localhost:8000/history
```

#### Descargar CSV
```bash
curl -X GET http://localhost:8000/download -o transcripciones.csv
```

#### Ver estado
```bash
curl http://localhost:8000/health
```

## ğŸ’¬ GuÃ­a Completa de Uso del Agente Inteligente

El agente usa **function calling nativo de LangChain** para entender lenguaje natural. Esto significa:
- âœ… **No necesitas comandos especÃ­ficos** - habla naturalmente
- âœ… **Funciona en mÃºltiples idiomas** - espaÃ±ol, inglÃ©s, etc.
- âœ… **Extrae parÃ¡metros automÃ¡ticamente** - entiende nÃºmeros, tÃ©rminos de bÃºsqueda, etc.
- âœ… **Sin palabras clave rÃ­gidas** - mÃºltiples formas de pedir lo mismo

### ğŸ“‹ Consultar Historial de Transcripciones

El agente entiende muchas variaciones naturales:

```bash
# EspaÃ±ol formal
curl -X POST http://localhost:8000/agent -F "message=dame el historial de transcripciones"

# EspaÃ±ol casual
curl -X POST http://localhost:8000/agent -F "message=muÃ©strame quÃ© transcripciones tienes guardadas"

# InglÃ©s
curl -X POST http://localhost:8000/agent -F "message=show me the transcription history"

# Muy casual
curl -X POST http://localhost:8000/agent -F "message=quÃ© has transcrito?"

# Pregunta directa
curl -X POST http://localhost:8000/agent -F "message=cuÃ¡ntas transcripciones hay?"

# Una sola palabra tambiÃ©n funciona
curl -X POST http://localhost:8000/agent -F "message=historial"
```

### ğŸ”¢ Con LÃ­mites EspecÃ­ficos

El LLM **extrae automÃ¡ticamente** el nÃºmero del mensaje:

```bash
# Las Ãºltimas 3
curl -X POST http://localhost:8000/agent -F "message=muÃ©strame las Ãºltimas 3 transcripciones"

# Las 5 mÃ¡s recientes
curl -X POST http://localhost:8000/agent -F "message=ensÃ©Ã±ame las 5 transcripciones mÃ¡s recientes"

# Solo 2
curl -X POST http://localhost:8000/agent -F "message=dame solo 2 del historial"

# Las 10 mÃ¡s nuevas
curl -X POST http://localhost:8000/agent -F "message=lista las 10 mÃ¡s nuevas"
```

### ğŸ” BÃºsquedas con Filtros

El LLM **extrae el tÃ©rmino de bÃºsqueda** automÃ¡ticamente:

```bash
# Buscar por palabra clave
curl -X POST http://localhost:8000/agent -F "message=busca transcripciones que mencionen reuniÃ³n"

# Buscar contenido especÃ­fico
curl -X POST http://localhost:8000/agent -F "message=encuentra transcripciones sobre proyecto"

# BÃºsqueda casual
curl -X POST http://localhost:8000/agent -F "message=hay algo transcrito sobre inteligencia artificial?"

# Con comillas para frases exactas
curl -X POST http://localhost:8000/agent -F "message=busca reuniÃ³n importante"
```

### ğŸ§ Transcribir Audio

#### Con archivo adjunto nuevo

```bash
# Formal
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe este archivo de audio" \
  -F "file=@mi_audio.mp3"

# Casual
curl -X POST http://localhost:8000/agent \
  -F "message=pÃ¡same esto a texto porfa" \
  -F "file=@podcast.wav"

# InglÃ©s
curl -X POST http://localhost:8000/agent \
  -F "message=convert this audio to text" \
  -F "file=@interview.m4a"

# Muy directo
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe" \
  -F "file=@meeting.mp3"

# Con contexto
curl -X POST http://localhost:8000/agent \
  -F "message=necesito transcribir esta reuniÃ³n importante" \
  -F "file=@reunion-enero.mp3"
```

#### Con archivo que ya estÃ¡ en uploads

Si ya tienes archivos en `data/audio/uploads/`:

```bash
# Referencia directa al archivo
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe el archivo podcast-ep1.mp3" \
  -F "file=@data/audio/uploads/podcast-ep1.mp3"

# Forma mÃ¡s natural
curl -X POST http://localhost:8000/agent \
  -F "message=pasa a texto el archivo entrevista.wav que tengo en uploads" \
  -F "file=@data/audio/uploads/entrevista.wav"

# Muy directo
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe reuniÃ³n-2024.mp3" \
  -F "file=@data/audio/uploads/reuniÃ³n-2024.mp3"

# Con contexto adicional
curl -X POST http://localhost:8000/agent \
  -F "message=necesito transcribir el audio conferencia.m4a que subÃ­ antes" \
  -F "file=@data/audio/uploads/conferencia.m4a"
```

### ğŸŒ Multi-idioma (Sin Cambiar CÃ³digo)

El agente entiende mÃºltiples idiomas automÃ¡ticamente:

```bash
# EspaÃ±ol
curl -X POST http://localhost:8000/agent -F "message=dame el historial"

# InglÃ©s
curl -X POST http://localhost:8000/agent -F "message=give me the history"

# FrancÃ©s
curl -X POST http://localhost:8000/agent -F "message=montre-moi l'historique"

# PortuguÃ©s
curl -X POST http://localhost:8000/agent -F "message=mostre-me o histÃ³rico"

# Mezcla de idiomas (code-switching)
curl -X POST http://localhost:8000/agent -F "message=show me las Ãºltimas transcripciones"
```

### ğŸ¯ Ejemplos de ExtracciÃ³n AutomÃ¡tica de ParÃ¡metros

El LLM entiende contexto y extrae valores sin necesidad de formato especÃ­fico:

```bash
# Extrae limit=10 automÃ¡ticamente
curl -X POST http://localhost:8000/agent -F "message=muÃ©strame las 10 Ãºltimas transcripciones"

# Extrae search=AI automÃ¡ticamente
curl -X POST http://localhost:8000/agent -F "message=busca transcripciones que hablen de AI"

# Extrae limit=5 y entiende recientes
curl -X POST http://localhost:8000/agent -F "message=dame las 5 mÃ¡s nuevas"

# Extrae search=proyecto y busca
curl -X POST http://localhost:8000/agent -F "message=hay transcripciones sobre el proyecto?"

# CombinaciÃ³n de parÃ¡metros
curl -X POST http://localhost:8000/agent -F "message=muÃ©strame las Ãºltimas 3 que mencionen reuniÃ³n"
```

### ğŸ’¬ Conversaciones Naturales

El agente maneja preguntas abiertas e informales:

```bash
# Pregunta abierta
curl -X POST http://localhost:8000/agent -F "message=quÃ© puedes hacer?"

# ExploraciÃ³n
curl -X POST http://localhost:8000/agent -F "message=tengo audios para transcribir"

# Contexto informal
curl -X POST http://localhost:8000/agent -F "message=hola, necesito ver quÃ© he transcrito antes"

# InstrucciÃ³n directa
curl -X POST http://localhost:8000/agent -F "message=lista todo lo que tienes"

# Sin mencionar transcripciÃ³n
curl -X POST http://localhost:8000/agent -F "message=quÃ© archivos has procesado?"

# Pregunta indirecta
curl -X POST http://localhost:8000/agent -F "message=recuerdas quÃ© has transcrito?"

# Contexto implÃ­cito
curl -X POST http://localhost:8000/agent -F "message=ensÃ©Ã±ame lo que tienes guardado"
```

### ğŸ§ª Flujo Completo de Ejemplo

```bash
# 1. Transcribir un nuevo archivo
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe este podcast" \
  -F "file=@mi_podcast.mp3"

# Respuesta:
# "TranscripciÃ³n completada:
#  Archivo: mi_podcast.mp3
#  DuraciÃ³n: 125.34 segundos
#  TranscripciÃ³n: [texto transcrito...]"

# 2. Ver el historial
curl -X POST http://localhost:8000/agent \
  -F "message=muÃ©strame quÃ© has transcrito"

# Respuesta:
# "Historial de transcripciones recientes:
#  ğŸ“„ mi_podcast.mp3
#  ğŸ“… 2026-01-29 15:30:00
#  ğŸ“ [primeras 100 palabras...]"

# 3. Buscar contenido especÃ­fico
curl -X POST http://localhost:8000/agent \
  -F "message=busca transcripciones que mencionen inteligencia artificial"

# Respuesta:
# "Se encontraron 2 transcripciones que contienen 'inteligencia artificial':
#  [resultados filtrados...]"

# 4. Ver solo las Ãºltimas 2
curl -X POST http://localhost:8000/agent \
  -F "message=dame las 2 mÃ¡s recientes"

# Respuesta:
# "Ãšltimas 2 transcripciones:
#  1. mi_podcast.mp3 - 2026-01-29 15:30:00
#  2. [anterior]..."
```

### ğŸ¨ Variaciones Creativas que Funcionan

Gracias al function calling, estas variaciones **todas funcionan**:

```bash
# Coloquial
curl -X POST http://localhost:8000/agent -F "message=a ver quÃ© tengo por aquÃ­"

# Formal
curl -X POST http://localhost:8000/agent -F "message=por favor proporcione el registro histÃ³rico"

# Pregunta
curl -X POST http://localhost:8000/agent -F "message=cuÃ¡ntos audios he transcrito ya?"

# Imperativo suave
curl -X POST http://localhost:8000/agent -F "message=podrÃ­as mostrarme el historial"

# Con urgencia
curl -X POST http://localhost:8000/agent -F "message=necesito urgentemente ver las transcripciones anteriores"

# TÃ©cnico
curl -X POST http://localhost:8000/agent -F "message=dump del historial"

# Muy simple
curl -X POST http://localhost:8000/agent -F "message=lista"
```

### âš¡ Por QuÃ© Funciona Esto

**Antes** (sistemas con palabras clave):
- âŒ Solo funcionaba: "historial", "show history"
- âŒ Fallaba con: "quÃ© has transcrito?", "muÃ©strame todo"
- âŒ RequerÃ­a comandos exactos
- âŒ No entendÃ­a contexto ni variaciones

**Ahora** (con function calling nativo):
- âœ… Entiende **intenciÃ³n**, no solo palabras exactas
- âœ… Extrae **parÃ¡metros automÃ¡ticamente** del mensaje
- âœ… Funciona en **mÃºltiples idiomas**
- âœ… Maneja **variaciones naturales** del lenguaje
- âœ… **Sin condicionales** `if/elif` en el cÃ³digo
- âœ… **Extensible**: agregar herramientas no requiere cambiar lÃ³gica

### ğŸ”§ CÃ³mo Funciona Internamente

```python
# El usuario escribe en lenguaje natural
"dame las Ãºltimas 5 transcripciones"

# El LLM analiza el mensaje + descripciones de herramientas
# y genera automÃ¡ticamente un tool_call:
{
  "name": "query_history",
  "args": {"limit": 5}
}

# El agente ejecuta la herramienta sin if/elif
result = tools["query_history"]._run(limit=5)
```

**DocumentaciÃ³n tÃ©cnica completa**: Ver `docs/architecture.md` para detalles sobre la implementaciÃ³n del function calling.

## ğŸŒ DocumentaciÃ³n

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“ Estructura del Proyecto

```
Modulo2-1/
â”œâ”€â”€ src/                    # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ api_server.py      # Servidor API FastAPI
â”‚   â”œâ”€â”€ agent.py           # Agente principal con LangChain
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ prompts/           # Plantillas de prompts
â”‚   â”‚   â””â”€â”€ agent_prompt.md
â”‚   â””â”€â”€ tools/             # Herramientas del agente
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ transcriber.py # TranscripciÃ³n con Whisper
â”‚       â””â”€â”€ history.py     # GestiÃ³n de historial
â”œâ”€â”€ data/                  # Datos de la aplicaciÃ³n
â”‚   â”œâ”€â”€ audio/            # Archivos de audio
â”‚   â”‚   â””â”€â”€ uploads/      # Subidas de usuario
â”‚   â””â”€â”€ transcriptions/   # Resultados
â”‚       â””â”€â”€ output/
â”‚           â””â”€â”€ history.csv
â”œâ”€â”€ tests/                # Pruebas unitarias
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ start_server.sh
â”œâ”€â”€ stop_server.sh
â”œâ”€â”€ start_server.bat
â”œâ”€â”€ stop_server.bat
â””â”€â”€ README.md
```

## ğŸµ Formatos de Audio Soportados

- MP3 (.mp3)
- WAV (.wav)
- M4A (.m4a)
- OGG (.ogg)
- FLAC (.flac)
- MP4 (.mp4) - solo audio

## ğŸ§  Modelos de Deepgram

| Modelo | Velocidad | PrecisiÃ³n | Costo | Recomendado para |
|--------|-----------|-----------|-------|------------------|
| nova-2 | â­â­â­â­â­ | â­â­â­â­â­ | Bajo | **Uso general** âœ… (Ãšltima generaciÃ³n) |
| nova | â­â­â­â­â­ | â­â­â­â­ | Bajo | Buena relaciÃ³n calidad-precio |
| base | â­â­â­â­ | â­â­â­ | Muy bajo | TranscripciÃ³n bÃ¡sica |
| enhanced | â­â­â­ | â­â­â­â­â­ | Alto | MÃ¡xima precisiÃ³n |

**RecomendaciÃ³n**: Usa `nova-2` para mejor rendimiento y precisiÃ³n (modelo por defecto).

**CaracterÃ­sticas de Nova-2**:
- ğŸš€ Velocidad ultrarrÃ¡pida (tiempo real)
- ğŸ¯ Mayor precisiÃ³n que modelos anteriores
- ğŸŒ Soporte para 100+ idiomas
- ğŸ’° Mejor costo-beneficio

## ğŸ“Š Formato CSV del Historial

El historial se guarda automÃ¡ticamente en `data/transcriptions/output/history.csv`:

```csv
timestamp,filename,duration_seconds,model,transcription_text
2026-01-29 10:30:00,podcast.mp3,3.45,deepgram-nova-2,"Texto transcrito..."
2026-01-29 11:45:00,interview.wav,2.87,deepgram-nova-2,"Otra transcripciÃ³n..."
```

**Nota**: `duration_seconds` representa el tiempo de procesamiento de la API (generalmente < 5 segundos).

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar modelo de Deepgram

En `src/tools/transcriber.py`, modifica el valor por defecto:

```python
model: str = Field(
    default="nova-2",  # Opciones: nova-2, nova, base, enhanced
    description="Deepgram model to use..."
)
```

O especifica el modelo en la llamada al agente:
```bash
curl -X POST http://localhost:8000/agent \
  -F "message=transcribe este audio usando el modelo enhanced" \
  -F "file=@audio.mp3"
```

### Cambiar modelo de Groq LLM

En `src/agent.py`, lÃ­nea del modelo:

```python
model_name="llama-3.3-70b-versatile",  # Opciones: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
```

**Nota**: El modelo debe soportar **function calling** para que el agente funcione correctamente.

## ğŸ› Troubleshooting

### Error: "GROQ_API_KEY not configured"

- AsegÃºrate de haber creado el archivo `.env`
- Verifica que tu API key estÃ© correctamente copiada
- No incluyas comillas alrededor de la API key

### Error: "DEEPGRAM_API_KEY not configured"

- ObtÃ©n tu API key en [https://console.deepgram.com](https://console.deepgram.com)
- AgrÃ©gala al archivo `.env`:
  ```bash
  DEEPGRAM_API_KEY=tu_deepgram_key_aqui
  ```
- Verifica que tengas crÃ©ditos disponibles en tu cuenta

### Error de Deepgram API

```bash
# Verificar que la API key funciona
curl -X GET "https://api.deepgram.com/v1/projects" \
  -H "Authorization: Token TU_DEEPGRAM_API_KEY"
```

### Audio no se transcribe correctamente

- Verifica que el formato sea compatible (mp3, wav, m4a, ogg, flac, mp4)
- Usa un modelo de mayor calidad (`enhanced` o `nova-2`)
- Especifica el idioma si es necesario:
  ```bash
  curl -X POST http://localhost:8000/agent \
    -F "message=transcribe este audio en espaÃ±ol" \
    -F "file=@audio.mp3"
  ```

### TranscripciÃ³n lenta o timeout

- Deepgram API es muy rÃ¡pida (generalmente < 5 segundos)
- Si experimentas lentitud, verifica tu conexiÃ³n a internet
- Revisa el status de Deepgram: [https://status.deepgram.com](https://status.deepgram.com)

## ğŸ§  Â¿QuÃ© es Function Calling?

Function calling es una capacidad nativa de los LLMs modernos donde el modelo puede **generar estructuras de llamada a funciones** basÃ¡ndose en descripciones semÃ¡nticas.

### âŒ Antes (Sistemas tradicionales con palabras clave)
```python
if "transcribe" in message or "transcribir" in message:
    use_transcribe_tool()
elif "historial" in message or "history" in message:
    use_history_tool()
# ... mÃ¡s condicionales ...
```

**Problemas**:
- Solo funciona con palabras especÃ­ficas
- No escala (cada herramienta = mÃ¡s condicionales)
- No entiende variaciones del lenguaje
- DifÃ­cil de mantener

### âœ… Ahora (Function Calling nativo)
```python
# 1. Vincular herramientas al LLM con descripciones
llm_with_tools = llm.bind_tools([
    TranscribeAudioTool(),  # "Transcribes audio files..."
    QueryHistoryTool(),     # "Queries transcription history..."
])

# 2. El LLM decide automÃ¡ticamente
response = llm_with_tools.invoke(user_message)

# 3. Ejecutar sin condicionales
if response.tool_calls:
    result = tools[response.tool_calls[0]['name']]._run(**response.tool_calls[0]['args'])
```

**Ventajas**:
- âœ… Entiende intenciÃ³n, no solo palabras
- âœ… Funciona en mÃºltiples idiomas automÃ¡ticamente
- âœ… Extrae parÃ¡metros del mensaje del usuario
- âœ… Agregar herramientas no requiere cambiar cÃ³digo

**ğŸ“– DocumentaciÃ³n completa**: Ver `docs/architecture.md` para anÃ¡lisis tÃ©cnico detallado sobre la implementaciÃ³n del function calling.

## ğŸ“š Recursos

- [Groq Documentation](https://console.groq.com/docs)
- [Deepgram API](https://developers.deepgram.com/)
- [OpenAI's Whisper](https://github.com/openai/whisper)
- [LangChain Function Calling](https://python.langchain.com/docs/modules/model_io/chat/function_calling)
- [FastAPI](https://fastapi.tiangolo.com/)

## ğŸ§ª Testing

### Probar herramientas individuales

```bash
python tests/test_tools.py
```

Con pytest (recomendado):
```bash
pip install pytest
pytest tests/
```

### Probar servidor local

```bash
python src/api_server.py
curl http://localhost:8000/health
```

## ğŸ—ï¸ Arquitectura TÃ©cnica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API FastAPI                        â”‚
â”‚           (Servidor REST)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Mensaje del usuario
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Agente Inteligente (Function Calling)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  LLM (Groq Llama 3.3 70B)                â”‚  â”‚
â”‚  â”‚  â€¢ Lee descripciones de herramientas     â”‚  â”‚
â”‚  â”‚  â€¢ Genera tool_calls automÃ¡ticamente     â”‚  â”‚
â”‚  â”‚  â€¢ Extrae parÃ¡metros del mensaje         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           â”‚           â”‚
         â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transcriber  â”‚ â”‚  Query   â”‚ â”‚    Save     â”‚
â”‚   Tool       â”‚ â”‚ History  â”‚ â”‚ Transcribe  â”‚
â”‚              â”‚ â”‚   Tool   â”‚ â”‚    Tool     â”‚
â”‚ â€¢ Deepgram   â”‚ â”‚          â”‚ â”‚             â”‚
â”‚   Nova-2 API â”‚ â”‚          â”‚ â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â”‚               â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   CSV Historial      â”‚
                   â”‚  (Pandas + CSV)      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

- **API**: FastAPI + Uvicorn
- **LLM**: Groq (Llama 3.3 70B Versatile) - 14,400 peticiones/dÃ­a gratis
- **TranscripciÃ³n**: Deepgram API (Nova-2) - $200 en crÃ©ditos iniciales
- **Framework**: LangChain con **Function Calling nativo**
- **Agent Pattern**: Inteligencia basada en descripciones semÃ¡nticas, sin condicionales
- **Persistencia**: Pandas + CSV
- **ConfiguraciÃ³n**: python-dotenv

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para detalles.

---

## ğŸ¯ Resumen

Este proyecto implementa un **agente de IA verdaderamente inteligente** que entiende lenguaje natural gracias a **function calling nativo**:

- ğŸ’¬ **Habla naturalmente** - No necesitas comandos especÃ­ficos
- ğŸŒ **Multi-idioma automÃ¡tico** - Funciona en cualquier idioma sin configuraciÃ³n
- ğŸ”§ **Extensible sin fricciÃ³n** - Agrega herramientas con descripciones, sin modificar lÃ³gica
- âš¡ **Sin condicionales** - Cero `if/elif` basados en palabras clave
- ğŸ¯ **ExtracciÃ³n inteligente** - El LLM identifica parÃ¡metros automÃ¡ticamente

**ğŸ“– Para detalles tÃ©cnicos completos**: Consulta `docs/architecture.md`

---

â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub
